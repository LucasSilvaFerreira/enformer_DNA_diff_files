{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34888ffe",
   "metadata": {
    "id": "DjPiVyaYAdUo",
    "papermill": {
     "duration": 0.031685,
     "end_time": "2023-06-03T00:24:43.306307",
     "exception": false,
     "start_time": "2023-06-03T00:24:43.274622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f2f871a",
   "metadata": {
    "id": "lD-o-nkTiFlR",
    "papermill": {
     "duration": 0.026934,
     "end_time": "2023-06-03T00:24:43.360906",
     "exception": false,
     "start_time": "2023-06-03T00:24:43.333972",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### TODO:\n",
    "-  ADD the training sequences (see how to get it on : https://github.com/pinellolab/DNA-Diffusion/blob/main/src/dnadiffusion/data/K562_hESCT0_HepG2_GM12878_12k_sequences_per_group.txt). Capture 200 nucleotide regions from the center of these coordinates (check bedtools)\n",
    "-  Lets try to have table with all the endogenous sequences, but for NOW just 1k regions from the training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8860bc01-edcf-4927-855f-57d21aa50db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOW TO USE\n",
    "#!papermill split_new_5_31_2023_enformer_CAGE_DNAse_bias_experiment.ipynb demo_out_param.ipynb -p SLICE 8 -P SPLIT_LEN 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee8e84ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-6toGDnw8x0t",
    "outputId": "0af98124-4f36-4c23-ac6b-faa481b33a14",
    "papermill": {
     "duration": 0.034344,
     "end_time": "2023-06-03T00:24:43.423694",
     "exception": false,
     "start_time": "2023-06-03T00:24:43.389350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6cf730a",
   "metadata": {
    "papermill": {
     "duration": 0.0361,
     "end_time": "2023-06-03T00:24:43.487834",
     "exception": false,
     "start_time": "2023-06-03T00:24:43.451734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install papermill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a6317dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pol8ttIT-5Tf",
    "outputId": "d2096f04-5ef5-4aa4-87d7-c5b9a0d05d76",
    "papermill": {
     "duration": 0.035321,
     "end_time": "2023-06-03T00:24:43.552601",
     "exception": false,
     "start_time": "2023-06-03T00:24:43.517280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install kipoiseq==0.5.2 \n",
    "#!pip install igv_notebook\n",
    "#!pip install pyBigWig\n",
    "#!pip install joblib\n",
    "#!pip install seaborn\n",
    "#!pip install matplotlib\n",
    "#!pip install tensorflow-hub\n",
    "#!pip install imagio\n",
    "#!pip install pyfaidx\n",
    "#!pip install tqdm\n",
    "#!pip install wget\n",
    "#!apt-get install bedtools\n",
    "#!pip install pybedtools\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85febff9-10b9-4149-a110-dbd3ef36c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ba57262",
   "metadata": {
    "papermill": {
     "duration": 0.028767,
     "end_time": "2023-06-03T00:24:43.610324",
     "exception": false,
     "start_time": "2023-06-03T00:24:43.581557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "class DataSplitter:\n",
    "    def __init__(self, df: pd.DataFrame, num_splits: int, seed=42):\n",
    "        self.df = shuffle(df, random_state=seed)\n",
    "        self.num_splits = num_splits\n",
    "\n",
    "    def get_slice(self, i: int):\n",
    "        if i < 0 or i >= self.num_splits:\n",
    "            raise ValueError(f'Slice index out of range. Must be between 0 and {self.num_splits-1}')\n",
    "\n",
    "        # Compute slice size\n",
    "        slice_size = len(self.df) // self.num_splits\n",
    "\n",
    "        # Determine start and end indices of slice\n",
    "        start = i * slice_size\n",
    "        end = start + slice_size if i < self.num_splits - 1 else None  # Take rest of df for last slice\n",
    "\n",
    "        return self.df.iloc[start:end]\n",
    "\n",
    "    def process_slice(self, processing_func, i: int):\n",
    "        df_slice = self.get_slice(i)\n",
    "        return processing_func(df_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "251638ae",
   "metadata": {
    "id": "U2OdpOZy_did",
    "papermill": {
     "duration": 4.848709,
     "end_time": "2023-06-03T00:24:48.488204",
     "exception": false,
     "start_time": "2023-06-03T00:24:43.639495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import joblib\n",
    "import gzip\n",
    "import kipoiseq\n",
    "from kipoiseq import Interval\n",
    "import pyfaidx\n",
    "import pyBigWig\n",
    "import igv_notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import os \n",
    "import pickle as pkl\n",
    "import wget \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# assert tf.config.list_physical_devices('GPU'), 'Start the colab kernel with GPU: Runtime -> Change runtime type -> GPU'\n",
    "\n",
    "# tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17359a11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9UdfwYXOkOK",
    "outputId": "11e17a9c-cb3f-4db8-a488-a0c16c315bbb",
    "papermill": {
     "duration": 0.046751,
     "end_time": "2023-06-03T00:24:48.572133",
     "exception": false,
     "start_time": "2023-06-03T00:24:48.525382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%cd /content/drive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8be9235f-d16f-4ea9-b464-451b5c158de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://storage.googleapis.com/tfhub-modules/deepmind/enformer/1.tar.gz\n",
    "#!tar -xf 1.tar.gz\n",
    "#!rm 1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21858b0-02aa-4430-93a8-93d030da186e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ab6861f-7242-448f-89f1-92a5fa3fa39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "!ls |  grep sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf12489",
   "metadata": {
    "papermill": {
     "duration": 0.305909,
     "end_time": "2023-06-03T00:24:48.915931",
     "exception": false,
     "start_time": "2023-06-03T00:24:48.610022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb534584",
   "metadata": {
    "papermill": {
     "duration": 0.034058,
     "end_time": "2023-06-03T00:24:48.985489",
     "exception": false,
     "start_time": "2023-06-03T00:24:48.951431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a835e9ea",
   "metadata": {
    "papermill": {
     "duration": 0.034956,
     "end_time": "2023-06-03T00:24:49.054925",
     "exception": false,
     "start_time": "2023-06-03T00:24:49.019969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ef430dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9pOaNfXI_IzS",
    "outputId": "e201cda3-ef77-48a4-9d09-8be1839160e3",
    "papermill": {
     "duration": 0.308902,
     "end_time": "2023-06-03T00:24:49.408394",
     "exception": false,
     "start_time": "2023-06-03T00:24:49.099492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir \"Enformer_Experiments\"\n",
    "#%cd Enformer_Experiments/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85833919",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54S6fo-fDlbE",
    "outputId": "fc9e1baf-1937-48b9-d50d-be5dc55708b4",
    "papermill": {
     "duration": 0.735951,
     "end_time": "2023-06-03T00:24:50.178784",
     "exception": false,
     "start_time": "2023-06-03T00:24:49.442833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "\n",
    "#transform_path = 'gs://dm-enformer/models/enformer.finetuned.SAD.robustscaler-PCA500-robustscaler.transform.pkl'\n",
    "model_path = '/.'   #'https://tfhub.dev/deepmind/enformer/1'\n",
    "fasta_file = '/data/genome.fa'\n",
    "#clinvar_vcf = 'data/clinvar.vcf.gz'\n",
    "#targets_txt = 'https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_human.txt'\n",
    "#file_url = 'https://github.com/pinellolab/DNA-Diffusion/raw/main/src/dnadiffusion/data/K562_hESCT0_HepG2_GM12878_12k_sequences_per_group.txt'\n",
    "train_data_path = '/data/K562_hESCT0_HepG2_GM12878_12k_sequences_per_group.txt'\n",
    "random_data_path = '/data/random_regions_train_generated_genome_10k.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5b5e1-8937-4504-8f8e-33017a517ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1da0afe7-6fb9-4e45-956b-82e84b181492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-06-05 10:23:15--  https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_human.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 800919 (782K) [text/plain]\n",
      "Saving to: ‘targets_human.txt’\n",
      "\n",
      "targets_human.txt   100%[===================>] 782.15K  4.91MB/s    in 0.2s    \n",
      "\n",
      "2023-06-05 10:23:15 (4.91 MB/s) - ‘targets_human.txt’ saved [800919/800919]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>genome</th>\n",
       "      <th>identifier</th>\n",
       "      <th>file</th>\n",
       "      <th>clip</th>\n",
       "      <th>scale</th>\n",
       "      <th>sum_stat</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>4675</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs10608</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:Clontech Human Universal Reference Total ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676</th>\n",
       "      <td>4676</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs10610</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:SABiosciences XpressRef Human Universal T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4677</th>\n",
       "      <td>4677</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs10612</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:Universal RNA - Human Normal Tissues Bioc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4678</th>\n",
       "      <td>4678</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs10615</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:adipose tissue, adult, pool1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4679</th>\n",
       "      <td>4679</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs10616</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:bladder, adult, pool1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>5308</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs14239</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:epithelioid sarcoma cell line:HS-ES-2R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>5309</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs14240</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:squamous cell lung carcinoma cell line:RE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5310</th>\n",
       "      <td>5310</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs14241</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:gastric cancer cell line:GSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>5311</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs14244</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:carcinoid cell line:NCI-H727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312</th>\n",
       "      <td>5312</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs14245</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:lung adenocarcinoma, papillary cell line:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  genome identifier  \\\n",
       "4675   4675       0  CNhs10608   \n",
       "4676   4676       0  CNhs10610   \n",
       "4677   4677       0  CNhs10612   \n",
       "4678   4678       0  CNhs10615   \n",
       "4679   4679       0  CNhs10616   \n",
       "...     ...     ...        ...   \n",
       "5308   5308       0  CNhs14239   \n",
       "5309   5309       0  CNhs14240   \n",
       "5310   5310       0  CNhs14241   \n",
       "5311   5311       0  CNhs14244   \n",
       "5312   5312       0  CNhs14245   \n",
       "\n",
       "                                                   file  clip  scale sum_stat  \\\n",
       "4675  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "4676  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "4677  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "4678  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "4679  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "...                                                 ...   ...    ...      ...   \n",
       "5308  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "5309  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "5310  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "5311  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "5312  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "\n",
       "                                            description  \n",
       "4675  CAGE:Clontech Human Universal Reference Total ...  \n",
       "4676  CAGE:SABiosciences XpressRef Human Universal T...  \n",
       "4677  CAGE:Universal RNA - Human Normal Tissues Bioc...  \n",
       "4678                  CAGE:adipose tissue, adult, pool1  \n",
       "4679                         CAGE:bladder, adult, pool1  \n",
       "...                                                 ...  \n",
       "5308        CAGE:epithelioid sarcoma cell line:HS-ES-2R  \n",
       "5309  CAGE:squamous cell lung carcinoma cell line:RE...  \n",
       "5310                  CAGE:gastric cancer cell line:GSS  \n",
       "5311                  CAGE:carcinoid cell line:NCI-H727  \n",
       "5312  CAGE:lung adenocarcinoma, papillary cell line:...  \n",
       "\n",
       "[638 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!cd data/ ; wget 'https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_human.txt'\n",
    "\n",
    "df_targets = pd.read_csv('/data/targets_human.txt', sep='\\t')\n",
    "df_targets[df_targets.apply(lambda x : '' in x['description'] and  'CAGE' in x['description'] , 1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99d9022b",
   "metadata": {
    "id": "asGb7Rj7CosW",
    "papermill": {
     "duration": 0.04041,
     "end_time": "2023-06-03T00:24:50.254976",
     "exception": false,
     "start_time": "2023-06-03T00:24:50.214566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data downloads \n",
    "(uncomment if data is not yet in your local Drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "634f7ed7",
   "metadata": {
    "papermill": {
     "duration": 0.042082,
     "end_time": "2023-06-03T00:24:50.332126",
     "exception": false,
     "start_time": "2023-06-03T00:24:50.290044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1630b491",
   "metadata": {
    "papermill": {
     "duration": 0.034332,
     "end_time": "2023-06-03T00:24:50.402013",
     "exception": false,
     "start_time": "2023-06-03T00:24:50.367681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "230ec95b",
   "metadata": {
    "id": "5Rd9dWPWCN_P",
    "papermill": {
     "duration": 0.041362,
     "end_time": "2023-06-03T00:24:50.477926",
     "exception": false,
     "start_time": "2023-06-03T00:24:50.436564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !wget -O - http://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz | gunzip -c > {fasta_file}\n",
    "# !ls data\n",
    "# !wget https://ftp.ncbi.nlm.nih.gov/pub/clinvar/vcf_GRCh38/clinvar.vcf.gz -O data/clinvar.vcf.gz\n",
    "# !wget https://hgdownload.cse.ucsc.edu/goldenpath/hg38/bigZips/hg38.chrom.sizes\n",
    "# !wget https://www.dropbox.com/s/a9ggrhn3626x0di/DNA_DIFFUSION_ALL_SEQS.txt?dl=1 -O  DNA_DIFFUSION_ALL_SEQS.txt\n",
    "# !wget https://www.encodeproject.org/files/ENCFF413AHU/@@download/ENCFF413AHU.bigWig\n",
    "# !wget https://www.encodeproject.org/files/ENCFF093VXI/@@download/ENCFF093VXI.bigWig\n",
    "# !wget https://github.com/pinellolab/DNA-Diffusion/raw/main/src/dnadiffusion/data/K562_hESCT0_HepG2_GM12878_12k_sequences_per_group.txt -O data/K562_hESCT0_HepG2_GM12878_12k_sequences_per_group.txt\n",
    "# !wget https://www.dropbox.com/s/oqpn784x34f6pcq/random_regions_train_generated_genome_10k.txt?dl=1 -O data/random_regions_train_generated_genome_10k.txt\n",
    "# !wget https://fantom.gsc.riken.jp/5/datafiles/reprocessed/hg38_latest/extra/CAGE_peaks/hg38_liftover+new_CAGE_peaks_phase1and2.bed.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9ef285c",
   "metadata": {
    "id": "EEjT3x2LGcwH",
    "papermill": {
     "duration": 0.044129,
     "end_time": "2023-06-03T00:24:50.556159",
     "exception": false,
     "start_time": "2023-06-03T00:24:50.512030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sizes = pd.read_table('/hg38.chrom.sizes', header=None).head(22)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19fa57e1",
   "metadata": {
    "id": "0D00-sjkBxFg",
    "papermill": {
     "duration": 0.033309,
     "end_time": "2023-06-03T00:24:50.622662",
     "exception": false,
     "start_time": "2023-06-03T00:24:50.589353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Enformer TensorFlow base code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc9520aa",
   "metadata": {
    "id": "8mD_0t5sB34G",
    "papermill": {
     "duration": 0.05157,
     "end_time": "2023-06-03T00:24:50.707557",
     "exception": false,
     "start_time": "2023-06-03T00:24:50.655987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 393216\n",
    "\n",
    "class Enformer:\n",
    "\n",
    "  def __init__(self, tfhub_url):\n",
    "    self._model = hub.load(model_path).model\n",
    "\n",
    "  def predict_on_batch(self, inputs):\n",
    "    predictions = self._model.predict_on_batch(inputs)\n",
    "    return {k: v.numpy() for k, v in predictions.items()}\n",
    "\n",
    "  @tf.function\n",
    "  def contribution_input_grad(self, input_sequence,\n",
    "                              target_mask, output_head='human'):\n",
    "    input_sequence = input_sequence[tf.newaxis]\n",
    "\n",
    "    target_mask_mass = tf.reduce_sum(target_mask)\n",
    "    with tf.GradientTape() as tape:\n",
    "      tape.watch(input_sequence)\n",
    "      prediction = tf.reduce_sum(\n",
    "          target_mask[tf.newaxis] *\n",
    "          self._model.predict_on_batch(input_sequence)[output_head]) / target_mask_mass\n",
    "\n",
    "    input_grad = tape.gradient(prediction, input_sequence) * input_sequence\n",
    "    input_grad = tf.squeeze(input_grad, axis=0)\n",
    "    return tf.reduce_sum(input_grad, axis=-1)\n",
    "\n",
    "\n",
    "class EnformerScoreVariantsRaw:\n",
    "\n",
    "  def __init__(self, tfhub_url, organism='human'):\n",
    "    self._model = Enformer(tfhub_url)\n",
    "    self._organism = organism\n",
    "  \n",
    "  def predict_on_batch(self, inputs):\n",
    "    ref_prediction = self._model.predict_on_batch(inputs['ref'])[self._organism]\n",
    "    alt_prediction = self._model.predict_on_batch(inputs['alt'])[self._organism]\n",
    "\n",
    "    return alt_prediction.mean(axis=1) - ref_prediction.mean(axis=1)\n",
    "\n",
    "\n",
    "class EnformerScoreVariantsNormalized:\n",
    "\n",
    "  def __init__(self, tfhub_url, transform_pkl_path,\n",
    "               organism='human'):\n",
    "    assert organism == 'human', 'Transforms only compatible with organism=human'\n",
    "    self._model = EnformerScoreVariantsRaw(tfhub_url, organism)\n",
    "    with tf.io.gfile.GFile(transform_pkl_path, 'rb') as f:\n",
    "      transform_pipeline = joblib.load(f)\n",
    "    self._transform = transform_pipeline.steps[0][1]  # StandardScaler.\n",
    "    \n",
    "  def predict_on_batch(self, inputs):\n",
    "    scores = self._model.predict_on_batch(inputs)\n",
    "    return self._transform.transform(scores)\n",
    "\n",
    "\n",
    "class EnformerScoreVariantsPCANormalized:\n",
    "\n",
    "  def __init__(self, tfhub_url, transform_pkl_path,\n",
    "               organism='human', num_top_features=500):\n",
    "    self._model = EnformerScoreVariantsRaw(tfhub_url, organism)\n",
    "    with tf.io.gfile.GFile(transform_pkl_path, 'rb') as f:\n",
    "      self._transform = joblib.load(f)\n",
    "    self._num_top_features = num_top_features\n",
    "    \n",
    "  def predict_on_batch(self, inputs):\n",
    "    scores = self._model.predict_on_batch(inputs)\n",
    "    return self._transform.transform(scores)[:, :self._num_top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07139fef",
   "metadata": {
    "id": "Ve13UD_fB_Ls",
    "papermill": {
     "duration": 0.051787,
     "end_time": "2023-06-03T00:24:50.792623",
     "exception": false,
     "start_time": "2023-06-03T00:24:50.740836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FastaStringExtractor:\n",
    "    \n",
    "    def __init__(self, fasta_file):\n",
    "        self.fasta = pyfaidx.Fasta(fasta_file)\n",
    "        self._chromosome_sizes = {k: len(v) for k, v in self.fasta.items()}\n",
    "\n",
    "    def extract(self, interval: Interval, **kwargs) -> str:\n",
    "        # Truncate interval if it extends beyond the chromosome lengths.\n",
    "        chromosome_length = self._chromosome_sizes[interval.chrom]\n",
    "        trimmed_interval = Interval(interval.chrom,\n",
    "                                    max(interval.start, 0),\n",
    "                                    min(interval.end, chromosome_length),\n",
    "                                    )\n",
    "        # pyfaidx wants a 1-based interval\n",
    "        sequence = str(self.fasta.get_seq(trimmed_interval.chrom,\n",
    "                                          trimmed_interval.start + 1,\n",
    "                                          trimmed_interval.stop).seq).upper()\n",
    "        # Fill truncated values with N's.\n",
    "        pad_upstream = 'N' * max(-interval.start, 0)\n",
    "        pad_downstream = 'N' * max(interval.end - chromosome_length, 0)\n",
    "        return pad_upstream + sequence + pad_downstream\n",
    "\n",
    "    def close(self):\n",
    "        return self.fasta.close()\n",
    "\n",
    "\n",
    "def variant_generator(vcf_file, gzipped=False):\n",
    "  \"\"\"Yields a kipoiseq.dataclasses.Variant for each row in VCF file.\"\"\"\n",
    "  def _open(file):\n",
    "    return gzip.open(vcf_file, 'rt') if gzipped else open(vcf_file)\n",
    "    \n",
    "  with _open(vcf_file) as f:\n",
    "    for line in f:\n",
    "      if line.startswith('#'):\n",
    "        continue\n",
    "      chrom, pos, id, ref, alt_list = line.split('\\t')[:5]\n",
    "      # Split ALT alleles and return individual variants as output.\n",
    "      for alt in alt_list.split(','):\n",
    "        yield kipoiseq.dataclasses.Variant(chrom=chrom, pos=pos,\n",
    "                                           ref=ref, alt=alt, id=id)\n",
    "\n",
    "\n",
    "def one_hot_encode(sequence):\n",
    "  return kipoiseq.transforms.functional.one_hot_dna(sequence).astype(np.float32)\n",
    "\n",
    "\n",
    "def variant_centered_sequences(vcf_file, sequence_length, gzipped=False,\n",
    "                               chr_prefix=''):\n",
    "  seq_extractor = kipoiseq.extractors.VariantSeqExtractor(\n",
    "    reference_sequence=FastaStringExtractor(fasta_file))\n",
    "\n",
    "  for variant in variant_generator(vcf_file, gzipped=gzipped):\n",
    "    interval = Interval(chr_prefix + variant.chrom,\n",
    "                        variant.pos, variant.pos)\n",
    "    interval = interval.resize(sequence_length)\n",
    "    center = interval.center() - interval.start\n",
    "\n",
    "    reference = seq_extractor.extract(interval, [], anchor=center)\n",
    "    alternate = seq_extractor.extract(interval, [variant], anchor=center)\n",
    "\n",
    "    yield {'inputs': {'ref': one_hot_encode(reference),\n",
    "                      'alt': one_hot_encode(alternate)},\n",
    "           'metadata': {'chrom': chr_prefix + variant.chrom,\n",
    "                        'pos': variant.pos,\n",
    "                        'id': variant.id,\n",
    "                        'ref': variant.ref,\n",
    "                        'alt': variant.alt}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "405e907e",
   "metadata": {
    "id": "CBKW-4H_CBlC",
    "papermill": {
     "duration": 0.044152,
     "end_time": "2023-06-03T00:24:50.870940",
     "exception": false,
     "start_time": "2023-06-03T00:24:50.826788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_tracks(tracks, interval, height=1.5, color='blue',set_y=False):\n",
    "  fig, axes = plt.subplots(len(tracks), 1, figsize=(20, height * len(tracks)), sharex=True)\n",
    "  for ax, (title, y) in zip(axes, tracks.items()):\n",
    "    ax.fill_between(np.linspace(interval.start, interval.end, num=len(y)), y, color=color)\n",
    "    ax.set_title(title)\n",
    "    sns.despine(top=True, right=True, bottom=True)\n",
    "  ax.set_xlabel(str(interval))\n",
    "  #plt.tight_layout()\n",
    "  if set_y:\n",
    "    plt.ylim(set_y[0],set_y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cece060b",
   "metadata": {
    "id": "5cBlnpxVCCSR",
    "papermill": {
     "duration": 13.059022,
     "end_time": "2023-06-03T00:25:03.964942",
     "exception": false,
     "start_time": "2023-06-03T00:24:50.905920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Enformer(model_path)\n",
    "#\n",
    "fasta_extractor = FastaStringExtractor(fasta_file)\n",
    "#fasta_extractor = FastaStringExtractor('/PHShome/lf588/enformerOPS/genome.fa')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ca303c3",
   "metadata": {
    "id": "W-erCIZuAkI9",
    "papermill": {
     "duration": 0.038085,
     "end_time": "2023-06-03T00:25:04.039769",
     "exception": false,
     "start_time": "2023-06-03T00:25:04.001684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EnformerOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a4fda1e",
   "metadata": {
    "id": "JrBOmrAqAbZW",
    "papermill": {
     "duration": 0.194771,
     "end_time": "2023-06-03T00:25:04.271128",
     "exception": false,
     "start_time": "2023-06-03T00:25:04.076357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EnformerOps:\n",
    "    def __init__(self):\n",
    "        self.tracks = []\n",
    "        self.input_sequences_file_path = None\n",
    "        self.interval_list = None\n",
    "        self.capture_bigwig_names = None\n",
    "        self.full_generated_range_start = None\n",
    "        self.full_generated_range_end = None\n",
    "        self.loaded_seqs = None\n",
    "    \n",
    "\n",
    "    def add_track(self, track):\n",
    "        \"\"\"\n",
    "        Adds a track to the list of tracks to be visualized.\n",
    "\n",
    "        Args:\n",
    "            track (dict): A dictionary specifying the track to be added. \n",
    "            Should have the keys \"name\", \"file\", \"color\", \"type\", and \"id\" \n",
    "            (if type is \"enformer\").\n",
    "        \"\"\"\n",
    "        self.tracks.append(track)\n",
    "\n",
    "    def remove_track(self, track_key):\n",
    "      \"\"\"\n",
    "      Removes track from track list.\n",
    "\n",
    "      Args:\n",
    "          track_key (str or list): Name of the track(s) to be deleted\n",
    "      \"\"\"\n",
    "\n",
    "      if type(track_key) == str:\n",
    "        self.tracks.remove(track_key)\n",
    "      elif type(track_key) == list:\n",
    "        for key in track_key:\n",
    "          self.tracks.remove(track_key)\n",
    "      else:\n",
    "        raise TypeError(\"track_key must be of type str or list\")\n",
    "\n",
    "    def load_data(self, input_sequences_file_path):\n",
    "      \n",
    "        if type(input_sequences_file_path) == list:\n",
    "          self.loaded_seqs =  [ [x] for x in input_sequences_file_path]\n",
    "          self.input_sequences_file_path = input_sequences_file_path\n",
    "        \n",
    "\n",
    "    def generate_plot_number(self, \n",
    "                             sequence_number_thousand, \n",
    "                             step=-1, \n",
    "                             interval_list=None,\n",
    "                             show_track=True, \n",
    "                             capture_bigwig_names=True,\n",
    "                             wildtype=False,\n",
    "                            insert_seq_directly=False,\n",
    "                            modify_prefix=''):\n",
    "        \"\"\"\n",
    "        Generates IGV tracks for a given sequence in a diffusion dataset.\n",
    "\n",
    "        Args:\n",
    "            sequence_number_thousand (int): The number of the sequence ID in \n",
    "            the diffusion sequences FASTA dataset.\n",
    "\n",
    "            step (int, optional): Which diffusion step to use. Default is -1, \n",
    "            which means the last diffusion step (i.e., the final diffused sequence).\n",
    "            \n",
    "            interval_list (list, optional): Coordinate to insert the 200 bp \n",
    "            sequence. Should be in BED format (chr, start, end). Default is None.\n",
    "            \n",
    "            show_track (bool, optional): Whether to generate IGV tracks as a result. \n",
    "            Default is True.\n",
    "            \n",
    "            capture_bigwig_names (bool, optional): Whether to output a list with\n",
    "            all IGV tracks generated and used (in case real bigwig files were used)\n",
    "            for the final visualization. Default is True.\n",
    "\n",
    "            wildtype (bool, False)\n",
    "            Dont insert and capture the wildtype sequence\n",
    "        Returns:\n",
    "            list: A list with the name of all bigwig files generated.\n",
    "        \"\"\"\n",
    "        capture_bigwig_names = [] # return the name of all bigwig \n",
    "        USE_INTERVAL = interval_list\n",
    "        if not interval_list:\n",
    "            USE_INTERVAL = self.interval_list # this should be your 200 bp region\n",
    "\n",
    "        if USE_INTERVAL is None:\n",
    "            raise ValueError(\"Interval list must be specified.\")\n",
    "\n",
    "        target_interval = kipoiseq.Interval(USE_INTERVAL[0], USE_INTERVAL[1], USE_INTERVAL[2])\n",
    "\n",
    "        chr_test = target_interval.resize(SEQUENCE_LENGTH).chr\n",
    "        start_test = target_interval.resize(SEQUENCE_LENGTH).start\n",
    "        end_test = target_interval.resize(SEQUENCE_LENGTH).end\n",
    "\n",
    "        seq_to_mod = fasta_extractor.extract(target_interval.resize(SEQUENCE_LENGTH))\n",
    "\n",
    "        all_seqs_test = self.loaded_seqs[sequence_number_thousand]\n",
    "\n",
    "\n",
    "        SEQ_IN = self.insert_seq(all_seqs_test[step], seq_to_mod, dont_insert=wildtype) # JUST THE LAST\n",
    "        predictions = self.predict_from_sequence(SEQ_IN)\n",
    "\n",
    "        mod_start = int(start_test + ((end_test - start_test)/2)) - int(114688/2)\n",
    "        mod_end = int(start_test + ((end_test - start_test)/2)) + int(114688/2)\n",
    "\n",
    "\n",
    "        self.full_generated_range_start = mod_start\n",
    "        self.full_generated_range_end = mod_end \n",
    "        self.full_generated_chr = chr_test\n",
    "\n",
    "\n",
    "        if show_track:\n",
    "            igv_notebook.init()\n",
    "            b = igv_notebook.Browser({\n",
    "                \"genome\": \"hg38\",\n",
    "                \"locus\": f\"{chr_test}:{mod_start}-{mod_end}\"\n",
    "            })\n",
    "        \n",
    "        for track in self.tracks:\n",
    "            #print (track)\n",
    "            if track['type'] == 'enformer':\n",
    "                id = track['id']\n",
    "                n = modify_prefix + track['name']\n",
    "                lg = track['log']\n",
    "\n",
    "                p_values = predictions[:, id]\n",
    "                if lg == True:\n",
    "                    p_values =np.log10(1 + predictions[:, id])\n",
    "                capture_bigwig_names.append(n+'.bw')\n",
    "                out_track = self._enformer_bigwig_creation(chr_test, mod_start, p_values, n) # change this pretiction t/name for a real thing\n",
    "                if show_track:\n",
    "                    b.load_track(out_track)\n",
    "\n",
    "            elif track['type'] == 'real':\n",
    "                n = track['name']\n",
    "                f = modify_prefix + track['file']\n",
    "                c = track['color']\n",
    "                capture_bigwig_names.append(f)\n",
    "                if show_track:\n",
    "                    b.load_track(self._generate_real_tracks(n, f, c))\n",
    "\n",
    "        self.capture_bigwig_names = capture_bigwig_names\n",
    "\n",
    "        return capture_bigwig_names\n",
    "\n",
    "\n",
    "    def capture_full_cords(self):\n",
    "      if self.full_generated_range_start:\n",
    "        return  self.full_generated_chr , self.full_generated_range_start, self.full_generated_range_end \n",
    "      else:\n",
    "        print ('Run generate_plot_number before it')\n",
    "\n",
    "\n",
    "    def extract_from_position(self, position, as_dataframe=False):\n",
    "        \"\"\"\n",
    "        Extracts data from the bigwig files generated by generate_plot_number for a given genomic region.\n",
    "\n",
    "        Args:\n",
    "            chr_name (str): The name of the chromosome.\n",
    "            start (int): The start position of the region.\n",
    "            end (int): The end position of the region.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of dictionaries containing the name of each bigwig file \n",
    "            and the values for the given region.\n",
    "        \"\"\"\n",
    "        if self.capture_bigwig_names is None:\n",
    "            raise ValueError(\"Must call generate_plot_number first to generate the bigwig files.\")\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for name in self.capture_bigwig_names:\n",
    "            bw = pyBigWig.open(name)\n",
    "            values = bw.values(position[0], position[1], position[2])\n",
    "            results.append({\n",
    "                'name': name,\n",
    "                'values': values\n",
    "            })\n",
    "        if as_dataframe:\n",
    "          results = pd.DataFrame({ k['name']: k['values'] for k in results })\n",
    "\n",
    "        return results\n",
    "\n",
    "    @staticmethod\n",
    "    def predict_from_sequence(input_sequence):\n",
    "      sequence_one_hot = one_hot_encode(input_sequence)\n",
    "      return model.predict_on_batch(sequence_one_hot[np.newaxis])['human'][0]\n",
    "\n",
    "    @staticmethod\n",
    "    def insert_seq(seq_x, seq_mod_in, dont_insert=False):\n",
    "        '''\n",
    "        This function inserts a sequence `seq_x` into a larger sequence `seq_mod_in`.\n",
    "        \n",
    "        Args:\n",
    "            seq_x (str): The sequence to be inserted into `seq_mod_in`.\n",
    "            seq_mod_in (str): The larger sequence that `seq_x` will be inserted into.\n",
    "            dont_insert (bool, optional): Whether or not to skip inserting `seq_x`. \n",
    "            If `True`, `seq_mod_in` will be returned unchanged. Default is `False`.\n",
    "        \n",
    "        Returns:\n",
    "            str: The modified sequence with `seq_x` inserted into `seq_mod_in`.\n",
    "        '''\n",
    "        seq_to_mod_array = np.array(list(seq_mod_in))\n",
    "        seq_mod_center = seq_to_mod_array.shape[0] // 2\n",
    "        if not dont_insert:\n",
    "            seq_to_mod_array[seq_mod_center - 100:seq_mod_center + 100] = np.array(list(seq_x))\n",
    "        # else:\n",
    "            # print('Keeping endogenous sequence...')\n",
    "        return ''.join(seq_to_mod_array)\n",
    "\n",
    "    @staticmethod\n",
    "    def _enformer_bigwig_creation(chr_name, start, values, track_name, color='BLUE'):\n",
    "        \"\"\"\n",
    "        Creates a bigwig file for an Enformer track.\n",
    "\n",
    "        Args:\n",
    "            chr_name (str): The name of the chromosome.\n",
    "            start (int): The start position of the track.\n",
    "            values (np.array): The values to be used in the track.\n",
    "            track_name (str): The name of the track.\n",
    "            color (str, optional): The color to use for the track. Default is 'BLUE'.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the name and path of the bigwig file,\n",
    "            as well as its format, display mode, and color.\n",
    "        \"\"\"\n",
    "    \n",
    "        t_name = f\"{track_name}.bw\"\n",
    "        !echo '' > $t_name\n",
    "        bw = pyBigWig.open(t_name, \"w\")\n",
    "        bw.addHeader([(chr_name, coord) for chr_name, coord in df_sizes.values])\n",
    "        values_conversion = (values * 1000 ).astype(np.int64) + 0.0\n",
    "        bw.addEntries(chr_name, [start + (128 * x) for x in range(values_conversion.shape[0])], values=values_conversion, span=128)\n",
    "\n",
    "        return {\n",
    "            \"name\": f\"{track_name}\",\n",
    "            \"path\": f\"{track_name}.bw\",\n",
    "            \"format\": \"bigwig\",\n",
    "            \"displayMode\": \"EXPANDED\",\n",
    "            \"color\": f\"{color}\",\n",
    "            \"height\": 100,\n",
    "        }\n",
    "\n",
    "    \n",
    "    def _generate_real_tracks(self, name, filename, color):\n",
    "        \"\"\"\n",
    "        Generates a real track for a given bigwig file.\n",
    "\n",
    "        Args:\n",
    "            name (str): The name of the track.\n",
    "            file (str): The name of the bigwig file to use for the track.\n",
    "            color (str): The color to use for the track.\n",
    "\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the name, path, format, display mode, and color of the track.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        chr_name, start, end = self.capture_full_cords()\n",
    "        t_name = f\"{name}_minimal.bw\"\n",
    "        !echo '' > $t_name\n",
    "        bw = pyBigWig.open(t_name, \"w\")\n",
    "        bw.addHeader([(chr_name, coord) for chr_name, coord in df_sizes.values])\n",
    "        bw_cut = pyBigWig.open(filename, \"r\")\n",
    "        values = np.array(bw_cut.values(chr_name, start, end))\n",
    "        \n",
    "        values_conversion = (values * 1000 ).astype(np.int64) + 0.0\n",
    "        print (values_conversion)\n",
    "        print (chr_name, start)\n",
    "        bw.addEntries(chr_name, [r for r in  range(start, start+len(values_conversion)) ] , values=list(values_conversion), span=1, step =1)\n",
    "        bw.close()\n",
    "        bw_cut.close()\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"name\": name,\n",
    "            \"path\": t_name,\n",
    "            \"format\": \"bigwig\",\n",
    "            \"displayMode\": \"EXPANDED\",\n",
    "            \"color\": color,\n",
    "            \"height\": 100,\n",
    "            }\n",
    "\n",
    "    def tiling(self, interval_to_window, window=2000, slice=200):\n",
    "            slice_len = int(((interval_to_window[2] + window) - (interval_to_window[1] - window)) / slice)\n",
    "            start_slice = (interval_to_window[1] - window)\n",
    "            slices_position = [[interval_to_window[0], start_slice + (slice * n), start_slice + ((slice * n) + slice)] for n in range(slice_len)]\n",
    "            return slices_position\n",
    "\n",
    "    def generate_tiling(self, coord_to_tile, gata_gene_region):\n",
    "        #TODO df_sizes currently hardcoded since I am not sure what this is\n",
    "        df_sizes = pd.read_table('hg38.chrom.sizes', header=None).head(22)\n",
    "        tiling_coords = self.tiling(coord_to_tile, window=2000)\n",
    "        regions_capture = []\n",
    "\n",
    "        t_name = \"tiling_vis_\"+str(coord_to_tile[1])+\"_\"+str(coord_to_tile[2])+\".bw\"\n",
    "        !rm $t_name\n",
    "        !echo '' > $t_name\n",
    "        bw_insert = pyBigWig.open(t_name, \"w\")\n",
    "        bw_insert.addHeader([(chr, coord) for chr, coord in df_sizes.values])\n",
    "\n",
    "        for t in tqdm(tiling_coords):\n",
    "            bw_list = self.generate_plot_number(120, 1, interval_list=t, show_track=False)\n",
    "            return_bw_by_tile = self.extract_from_position(gata_gene_region)\n",
    "            mean_values_region_cage = np.mean(return_bw_by_tile[1]['values']).astype(np.int64) + 0.0\n",
    "            bw_insert.addEntries(t[0], [t[1]], values=[mean_values_region_cage], span=200)\n",
    "            regions_capture.append(mean_values_region_cage)\n",
    "        \n",
    "        bw_insert.close()\n",
    "        return regions_capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db1deea7",
   "metadata": {
    "id": "ltdxfGi4BgYB",
    "papermill": {
     "duration": 0.047078,
     "end_time": "2023-06-03T00:25:04.359475",
     "exception": false,
     "start_time": "2023-06-03T00:25:04.312397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "class SEQ_EXTRACT:\n",
    "  def __init__(self, data):\n",
    "    self.data= pd.read_csv(data, sep='\\t')\n",
    "\n",
    "  def extract_seq (self, tag, cell_type):\n",
    "    return self.data.query(f'TAG == \"{tag}\" and CELL_TYPE\t == \"{cell_type}\" ').copy()\n",
    "  def __repr__(self):\n",
    "    display(self.data.groupby(['TAG', 'CELL_TYPE']).count())\n",
    "    return  'Data structure'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3572dfd",
   "metadata": {
    "papermill": {
     "duration": 0.051784,
     "end_time": "2023-06-03T00:25:04.454262",
     "exception": false,
     "start_time": "2023-06-03T00:25:04.402478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!wget https://www.dropbox.com/s/n549ucfqu0u9tu6/master_random_frezzed_regions_train_test_validation_generated_genome_all_dataset.txt?dl=1  -O  MASTER_DNA_DIFFUSION_ALL_SEQS.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb45dc4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "v-E0D5uEBjdr",
    "outputId": "64b9c0d4-7418-4711-c85d-f0a7880a0cbf",
    "papermill": {
     "duration": 3.475834,
     "end_time": "2023-06-03T00:25:07.970675",
     "exception": false,
     "start_time": "2023-06-03T00:25:04.494841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1bf67bd",
   "metadata": {
    "papermill": {
     "duration": 0.04615,
     "end_time": "2023-06-03T00:25:08.058038",
     "exception": false,
     "start_time": "2023-06-03T00:25:08.011888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -Add the random for our full dataset.\n",
    "# -Dont remove hesct0 (use h1esc) use NA for cage\n",
    "# -Generate 10k random sequences (remove regions with NN)\n",
    "# -Add the CAGE tss(1kb+/-) prediction for the other 3 celltypes on the 440k.\n",
    "# -Dont show tss in the final sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd0734d",
   "metadata": {
    "id": "G0B8DR-kAx4r",
    "papermill": {
     "duration": 0.063444,
     "end_time": "2023-06-03T00:25:08.158657",
     "exception": false,
     "start_time": "2023-06-03T00:25:08.095213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3d9b006",
   "metadata": {
    "id": "FhsuX1NarIBy",
    "papermill": {
     "duration": 0.05163,
     "end_time": "2023-06-03T00:25:08.250977",
     "exception": false,
     "start_time": "2023-06-03T00:25:08.199347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eops.add_track({\n",
    "#     'name': 'DNAse:hESC_enformer',\n",
    "#     'file': None,\n",
    "#     'color': 'BLUE',\n",
    "#     'type': 'enformer',\n",
    "#     'id': 123,\n",
    "#     'log': False\n",
    "# })\n",
    "\n",
    "def load_tracks_eops(eops):\n",
    "    \n",
    "    eops.add_track({\n",
    "        'name': 'DNASE:GM12878_enformer',\n",
    "        'file': None,\n",
    "        'color': 'BLUE',\n",
    "        'type': 'enformer',\n",
    "        'id': 12,\n",
    "        'log': False\n",
    "    })\n",
    "\n",
    "    eops.add_track({\n",
    "        'name': 'DNASE:K562_enformer',\n",
    "        'file': None,\n",
    "        'color': 'BLUE',\n",
    "        'type': 'enformer',\n",
    "        'id': 121,\n",
    "        'log': False\n",
    "    })\n",
    "\n",
    "    eops.add_track({\n",
    "        'name': 'DNASE:HepG2_enformer',\n",
    "        'file': None,\n",
    "        'color': 'BLUE',\n",
    "        'type': 'enformer',\n",
    "        'id': 27,\n",
    "        'log': False\n",
    "    })\n",
    "    \n",
    "    eops.add_track({\n",
    "        'name': 'DNASE:H1esc_enformer',\n",
    "        'file': None,\n",
    "        'color': 'BLUE',\n",
    "        'type': 'enformer',\n",
    "        'id': 19,\n",
    "        'log': False\n",
    "    })\n",
    "\n",
    "    eops.add_track({\n",
    "        'name': 'CAGE:K562_enformer',\n",
    "        'file': None,\n",
    "        'color': 'RED',\n",
    "        'type': 'enformer',\n",
    "        'id': 5111,\n",
    "        'log': True\n",
    "    })\n",
    "\n",
    "    eops.add_track({\n",
    "        'name': 'CAGE:GM12878_enformer',\n",
    "        'file': None,\n",
    "        'color': 'RED',\n",
    "        'type': 'enformer',\n",
    "        'id': 5110,\n",
    "        'log': True\n",
    "    })\n",
    "\n",
    "    eops.add_track({\n",
    "        'name': 'CAGE:HepG2_enformer',\n",
    "        'file': None,\n",
    "        'color': 'RED',\n",
    "        'type': 'enformer',\n",
    "        'id': 5109,\n",
    "        'log': True\n",
    "    })\n",
    "    \n",
    "    # eops.add_track({\n",
    "    #     'name': 'CAGE:hESC_enformer',\n",
    "    #     'file': None,\n",
    "    #     'color': 'RED',\n",
    "    #     'type': 'enformer',\n",
    "    #     'id': 500,\n",
    "    #     'log': True\n",
    "    # })\n",
    "\n",
    "    # eops.add_track({\n",
    "    #     'name': 'K562 DNASE REAL',\n",
    "    #     'file': 'ENCFF413AHU.bigWig',\n",
    "    #     'color': 'skyblue',\n",
    "    #     'type': 'real'\n",
    "    # })\n",
    "    # eops.add_track({\n",
    "    #     'name': 'GM12878 DNASE REAL',\n",
    "    #     'file': 'ENCFF093VXI.bigWig',\n",
    "    #     'color': 'skyblue',\n",
    "    #     'type': 'real'\n",
    "    # })\n",
    "\n",
    "    # eops.remove_track(['CAGE:hESC_enformer', 'DNAse:hESC_enformer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e20fc9cb",
   "metadata": {
    "papermill": {
     "duration": 0.340083,
     "end_time": "2023-06-03T00:25:08.629068",
     "exception": false,
     "start_time": "2023-06-03T00:25:08.288985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "118cbd3c",
   "metadata": {
    "id": "68dRvoOMVOD8",
    "papermill": {
     "duration": 0.035989,
     "end_time": "2023-06-03T00:25:08.702021",
     "exception": false,
     "start_time": "2023-06-03T00:25:08.666032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Enformer output analysis of training; random; and generated sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3841c091",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "yHmWLEV3Vcnf",
    "outputId": "f0862080-f53e-40ce-ac1a-e906ab0d9cc9",
    "papermill": {
     "duration": 0.043006,
     "end_time": "2023-06-03T00:25:08.780408",
     "exception": false,
     "start_time": "2023-06-03T00:25:08.737402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c22e28b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T00:25:08.864913Z",
     "iopub.status.busy": "2023-06-03T00:25:08.864257Z",
     "iopub.status.idle": "2023-06-03T00:25:08.867935Z",
     "shell.execute_reply": "2023-06-03T00:25:08.867288Z"
    },
    "papermill": {
     "duration": 0.044585,
     "end_time": "2023-06-03T00:25:08.868056",
     "exception": false,
     "start_time": "2023-06-03T00:25:08.823471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 6 hours  random\n",
    "# 20 hours promoters \n",
    "# 50 hours train/test/validation\n",
    "# 350 hours  GENERATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ab4f21c",
   "metadata": {
    "papermill": {
     "duration": 0.101644,
     "end_time": "2023-06-03T00:25:09.007683",
     "exception": false,
     "start_time": "2023-06-03T00:25:08.906039",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'data/'\n",
    "\n",
    "DEMO=True\n",
    "\n",
    "SPLIT_LEN = 10\n",
    "\n",
    "SLICE=0\n",
    "\n",
    "DEMO_SEQ = 100\n",
    "\n",
    "JUST_GENERATED=False\n",
    "\n",
    "SKIP_GENERATED=True\n",
    "\n",
    "SAVE_INTERVAL = 10\n",
    "\n",
    "\n",
    "ENHANCER_REGION =  'chrX_48782929_48783129'\n",
    "GENE_REGION = ['chrX', 48785536, 48787536] \n",
    "\n",
    "CUSTOM_MASTER_TABLE = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f911bbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENHANCER_REGION = ENHANCER_REGION.split('_')\n",
    "ENHANCER_REGION[1] = int(ENHANCER_REGION[1])\n",
    "ENHANCER_REGION[2] = int(ENHANCER_REGION[2])\n",
    "GENE_REGION =    GENE_REGION.split('_')\n",
    "GENE_REGION[1] = int(GENE_REGION[1])\n",
    "GENE_REGION[2] = int(GENE_REGION[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c667ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #processing DEMO as a string that returns a bool\n",
    "# if DEMO.upper() == 'TRUE':\n",
    "#     DEMO = True\n",
    "# if DEMO.upper() == 'FALSE':\n",
    "#     DEMO = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d88e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_using_master = '/MASTER_DNA_DIFFUSION_ALL_SEQS.txt'\n",
    "if CUSTOM_MASTER_TABLE:\n",
    "    table_using_master = CUSTOM_MASTER_TABLE\n",
    "\n",
    "SEQS = SEQ_EXTRACT(table_using_master)\n",
    "SEQS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b3dcb23-6c97-4573-8ed4-5e4a58a0a9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(472885, 7) before\n",
      "chrom                                                    chr14\n",
      "start                                                 92895634\n",
      "end                                                   92895834\n",
      "ID                            chr14_92895527_92895734_92895650\n",
      "CELL_TYPE                                              GM12878\n",
      "SEQUENCE     TCTATTTGTCAGGGTTTTCTTAGCATTAGTGACTCCATTTTGATTC...\n",
      "TAG                                                   training\n",
      "Name: 0, dtype: object before\n",
      "(47288, 7) after\n",
      "chrom                                                    chr17\n",
      "start                                                 13640800\n",
      "end                                                   13641000\n",
      "ID                            chr17_13640637_13640900_13640750\n",
      "CELL_TYPE                                               hESCT0\n",
      "SEQUENCE     CCAAAAGAAATGCAATTGTCTTAAGACCCTCTCCCTAGGGATCTCA...\n",
      "TAG                                                   training\n",
      "Name: 38857, dtype: object after\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_data = SEQS.data.copy()\n",
    "print (all_data.shape, 'before')\n",
    "print (all_data.iloc[0], 'before')\n",
    "\n",
    "\n",
    "\n",
    "# Initialize splitter\n",
    "splitter = DataSplitter(all_data, SPLIT_LEN)\n",
    "# Process first slice\n",
    "all_data = splitter.get_slice(SLICE)\n",
    "MODIFY_PREFIX= f'{str(SLICE)}_'\n",
    "\n",
    "print (all_data.shape, 'after')\n",
    "print (all_data.iloc[0], 'after')\n",
    "#run lucas_test\n",
    "#papermill  5_31_2023_enformer_CAGE_DNAse_bias_experiment.ipynb  demo.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "515c8d96",
   "metadata": {
    "id": "QXlgC8KwVXXY",
    "papermill": {
     "duration": 0.040633,
     "end_time": "2023-06-03T00:25:09.086545",
     "exception": false,
     "start_time": "2023-06-03T00:25:09.045912",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Random sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24f8f3c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "9cUZMtlaV43n",
    "outputId": "507c9390-c87f-433e-82ca-1dd8e9b1cde4",
    "papermill": {
     "duration": 290.560447,
     "end_time": "2023-06-03T00:29:59.687364",
     "exception": false,
     "start_time": "2023-06-03T00:25:09.126917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove all head 3\n",
      "['RANDOM_GENOME_REGIONS'] (496, 7)\n"
     ]
    }
   ],
   "source": [
    "if not JUST_GENERATED:\n",
    "  print('Remove all head 3')\n",
    "  eops = EnformerOps()\n",
    "  eops.load_data(SEQS.extract_seq('GENERATED', 'GM12878')['SEQUENCE'].values.tolist())\n",
    "  load_tracks_eops(eops) #loading the tracks\n",
    "\n",
    "  ran_seqs = all_data[all_data['TAG'] == 'RANDOM_GENOME_REGIONS'].copy()\n",
    "  print (ran_seqs['TAG'].unique(), ran_seqs.shape)\n",
    "\n",
    "  subset_ran_seqs = ran_seqs[['chrom', 'start', 'end', 'ID']]\n",
    "  #ran_seq_list = subset_ran_seqs.head(3).values.tolist() # removing demo\n",
    "\n",
    "  ran_seq_list = subset_ran_seqs.values.tolist() # removing demo\n",
    "  if DEMO:\n",
    "      ran_seq_list=ran_seq_list[:DEMO_SEQ]\n",
    "\n",
    "  captured_values = []\n",
    "  for s in ran_seq_list: \n",
    "      #print(s)\n",
    "      try:\n",
    "          s_in = [s[0], int(s[1]), int(s[2])]\n",
    "          id_seq = s[3] \n",
    "          list_bw = eops.generate_plot_number(0, interval_list=s_in, wildtype=True, \n",
    "                                            show_track=False, modify_prefix=MODIFY_PREFIX) \n",
    "      except RuntimeError:\n",
    "        # Infrequent \"the entries are out of order\" error for some random seqs \n",
    "          continue\n",
    "      try:\n",
    "          out_in = eops.extract_from_position(s_in, as_dataframe=True)\n",
    "          #print (out_in.shape)\n",
    "          out_in = out_in.mean()\n",
    "          out_in['SEQ_ID'] = id_seq\n",
    "          out_in['TARGET_NAME'] = 'ITSELF'\n",
    "          columns_names = out_in.copy()\n",
    "          captured_values.append( out_in  )\n",
    "      except ValueError:\n",
    "        # Infrequent \"All arrays must be of the same length\" error\n",
    "          continue\n",
    "\n",
    "  df_out = pd.DataFrame([x.values.tolist() for x in captured_values], columns=out_in.index)\n",
    "\n",
    "  df_out.to_csv(OUTPUT_PATH + '/' + MODIFY_PREFIX +'DNASE_RANDOM_SEQS.TXT', sep='\\t', index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8ff314d",
   "metadata": {
    "papermill": {
     "duration": 0.042772,
     "end_time": "2023-06-03T00:29:59.827211",
     "exception": false,
     "start_time": "2023-06-03T00:29:59.784439",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Promoters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "179906c4",
   "metadata": {
    "papermill": {
     "duration": 0.067425,
     "end_time": "2023-06-03T00:29:59.937164",
     "exception": false,
     "start_time": "2023-06-03T00:29:59.869739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ['RANDOM_GENOME_REGIONS']        (5000)    (MEASURING: 200bp)       #DNASE (K562,HEPG2,GM, H1ESC) # CAGE (K562,HEPG2,GM)\n",
    "# ['PROMOTERS']                    (20013)  (MEASURING: 2000bp)       #DNASE (K562,HEPG2,GM, H1ESC) # CAGE (K562,HEPG2,GM)\n",
    "# ['training' 'test' 'validation'] (47872)   (MEASURING: 200bp)       #DNASE (K562,HEPG2,GM, H1ESC) # CAGE (K562,HEPG2,GM)\n",
    "\n",
    "# #2X (ENHANCER AND GATA1)  #DNASE (K562,HEPG2,GM, H1ESC) # CAGE (K562,HEPG2,GM)\n",
    "# ['GENERATED']                    (400000)   (MEASURING: ENH(200bp) GATA1_GB( 7925bp) ) \n",
    "                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5074145f",
   "metadata": {
    "papermill": {
     "duration": 296.41806,
     "end_time": "2023-06-03T00:34:56.402374",
     "exception": false,
     "start_time": "2023-06-03T00:29:59.984314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove all head 3\n",
      "['PROMOTERS'] (1992, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598e28dfcbef41478d83a7c324d1e189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not JUST_GENERATED:\n",
    "  print('Remove all head 3')\n",
    "  eops = EnformerOps()\n",
    "  eops.load_data(SEQS.extract_seq('GENERATED', 'GM12878')['SEQUENCE'].values.tolist())\n",
    "  load_tracks_eops(eops) #loading the tracks\n",
    "\n",
    "  ran_seqs = all_data[all_data['TAG'] == 'PROMOTERS'].copy()\n",
    "  print (ran_seqs['TAG'].unique(), ran_seqs.shape)\n",
    "\n",
    "  subset_ran_seqs = ran_seqs[['chrom', 'start', 'end', 'ID']]\n",
    "  #ran_seq_list = subset_ran_seqs.head(3).values.tolist()\n",
    "  ran_seq_list = subset_ran_seqs.values.tolist()\n",
    "  if DEMO:\n",
    "      ran_seq_list=ran_seq_list[:DEMO_SEQ]\n",
    "\n",
    "  captured_values = []\n",
    "  for s in tqdm(ran_seq_list): \n",
    "      #print(s)\n",
    "      try:\n",
    "          s_in = [s[0], int(s[1]), int(s[2])]\n",
    "          id_seq = s[3] \n",
    "          list_bw = eops.generate_plot_number(0, interval_list=s_in, wildtype=True, \n",
    "                                            show_track=False, modify_prefix=MODIFY_PREFIX) \n",
    "      except RuntimeError:\n",
    "        # Infrequent \"the entries are out of order\" error for some random seqs \n",
    "          continue\n",
    "      try:\n",
    "          out_in = eops.extract_from_position(s_in, as_dataframe=True)\n",
    "          #print (out_in.shape)\n",
    "          out_in = out_in.mean()\n",
    "          out_in['SEQ_ID'] = id_seq\n",
    "          out_in['TARGET_NAME'] = 'ITSELF'\n",
    "          columns_names = out_in.copy()\n",
    "          captured_values.append( out_in  )\n",
    "      except ValueError:\n",
    "        # Infrequent \"All arrays must be of the same length\" error\n",
    "          continue\n",
    "\n",
    "  df_out = pd.DataFrame([x.values.tolist() for x in captured_values], columns=out_in.index)\n",
    "\n",
    "  df_out.to_csv(OUTPUT_PATH + '/' + MODIFY_PREFIX +'PROMOTERS_SEQS.TXT', sep='\\t', index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfa1db5e",
   "metadata": {
    "papermill": {
     "duration": 0.063137,
     "end_time": "2023-06-03T00:34:56.531650",
     "exception": false,
     "start_time": "2023-06-03T00:34:56.468513",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab22b78",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2023-06-03T00:34:56.599370",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove all head 3\n",
      "['training' 'test' 'validation'] (4819, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7861a9a59d448691befd92c8aa5c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if not JUST_GENERATED:\n",
    "#   print('Remove all head 3')\n",
    "#   eops = EnformerOps()\n",
    "#   eops.load_data(SEQS.extract_seq('GENERATED', 'GM12878')['SEQUENCE'].values.tolist())\n",
    "#   load_tracks_eops(eops) #loading the tracks\n",
    "\n",
    "#   ran_seqs = all_data[all_data['TAG'].apply(lambda x : x in {'training', 'test', 'validation'})].copy()\n",
    "#   print (ran_seqs['TAG'].unique(), ran_seqs.shape)\n",
    "#   subset_ran_seqs = ran_seqs[['chrom', 'start', 'end', 'ID']]\n",
    "#   #ran_seq_list = subset_ran_seqs.head(3).values.tolist()\n",
    "#   ran_seq_list = subset_ran_seqs.values.tolist()\n",
    "#   if DEMO:\n",
    "#       ran_seq_list=ran_seq_list[:DEMO_SEQ]\n",
    "\n",
    "#   captured_values = []\n",
    "#   for s in tqdm(ran_seq_list): \n",
    "#       #print(s)\n",
    "#       try:\n",
    "#           s_in = [s[0], int(s[1]), int(s[2])]\n",
    "#           id_seq = s[3] \n",
    "#           list_bw = eops.generate_plot_number(0, interval_list=s_in, wildtype=True, \n",
    "#                                             show_track=False, modify_prefix=MODIFY_PREFIX) \n",
    "#       except RuntimeError:\n",
    "#         # Infrequent \"the entries are out of order\" error for some random seqs \n",
    "#           continue\n",
    "#       try:\n",
    "#           out_in = eops.extract_from_position(s_in, as_dataframe=True)\n",
    "#           #print (out_in.shape)\n",
    "#           out_in = out_in.mean()\n",
    "#           out_in['SEQ_ID'] = id_seq\n",
    "#           out_in['TARGET_NAME'] = 'ITSELF'\n",
    "#           columns_names = out_in.copy()\n",
    "#           captured_values.append( out_in  )\n",
    "#       except ValueError:\n",
    "#         # Infrequent \"All arrays must be of the same length\" error\n",
    "#           continue\n",
    "\n",
    "#   df_out = pd.DataFrame([x.values.tolist() for x in captured_values], columns=out_in.index)\n",
    "\n",
    "#   df_out.to_csv(OUTPUT_PATH + '/' + MODIFY_PREFIX +'TRAINING_TEST_VALIDATION_SEQS.TXT', sep='\\t', index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e73c6855",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de37f8a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if SKIP_GENERATED==False:\n",
    "  print('Remove all head 3')\n",
    "  eops = EnformerOps()\n",
    "\n",
    "\n",
    "\n",
    "  load_tracks_eops(eops) #loading the tracks\n",
    "\n",
    "  ran_seqs = all_data[all_data['TAG'] == 'GENERATED'].copy()\n",
    "  subset_ran_seqs = ran_seqs[['SEQUENCE', 'ID']]\n",
    "  print ( all_data[all_data['TAG'] == 'GENERATED'].shape)\n",
    "  print (ran_seqs['TAG'].unique())\n",
    "\n",
    "  #ran_seq_list = subset_ran_seqs.head(3).values.tolist()\n",
    "  ran_seq_list = subset_ran_seqs.values.tolist()\n",
    "  if DEMO:\n",
    "      ran_seq_list=ran_seq_list[:DEMO_SEQ]\n",
    "\n",
    "\n",
    "\n",
    "  captured_values = []\n",
    "  captured_values_target = []\n",
    "  for e_n, s in enumerate(ran_seq_list): \n",
    "      \n",
    "      try:\n",
    "          s_in = s[1]\n",
    "          id_seq = s[0]   # aways inject a sequence\n",
    "          #print (id_seq)\n",
    "          eops.load_data([id_seq]) # This will be always zero (sequence passed using insert_seq_directly)\n",
    "          list_bw = eops.generate_plot_number(-1, interval_list=ENHANCER_REGION, wildtype=False, \n",
    "                                            show_track=False, modify_prefix=MODIFY_PREFIX) \n",
    "      except RuntimeError:\n",
    "        # Infrequent \"the entries are out of order\" error for some random seqs \n",
    "          continue\n",
    "      try:\n",
    "          out_in = eops.extract_from_position(ENHANCER_REGION, as_dataframe=True)\n",
    "          #print (out_in.shape)\n",
    "          out_in = out_in.mean()\n",
    "          out_in['SEQ_ID'] = s_in\n",
    "          out_in['TARGET_NAME'] = 'ENH_GATA1'\n",
    "          columns_names = out_in.copy()\n",
    "          captured_values.append( out_in  )\n",
    "          \n",
    "          out_in = eops.extract_from_position(GENE_REGION, as_dataframe=True)\n",
    "          #print (out_in.shape)\n",
    "          out_in = out_in.mean()\n",
    "          out_in['SEQ_ID'] = id_seq\n",
    "          out_in['TARGET_NAME'] = 'GATA1_TSS_2K'\n",
    "          columns_names = out_in.copy()\n",
    "          captured_values_target.append( out_in  )\n",
    "          \n",
    "      except ValueError:\n",
    "        # Infrequent \"All arrays must be of the same length\" error\n",
    "          continue\n",
    "\n",
    "      if (e_n !=0) and (e_n % SAVE_INTERVAL )==0:\n",
    "        print ('SAVING', e_n)\n",
    "        df_out_ENH =  pd.DataFrame([x.values.tolist() for x in captured_values],        columns=['ENHANCER_' + x for x in   out_in.index])\n",
    "        df_out_GENE = pd.DataFrame([x.values.tolist() for x in captured_values_target], columns=['GENE_' + x for x in       out_in.index])\n",
    "\n",
    "        df_out = pd.concat([df_out_ENH, df_out_GENE], axis=1)\n",
    "\n",
    "        df_out.to_csv(OUTPUT_PATH + '/' + MODIFY_PREFIX +'GENERATED_SEQS.TXT', sep='\\t', index=None)\n",
    "\n",
    "\n",
    "  print ('SAVING', e_n, 'Final_saving')\n",
    "  df_out_ENH =  pd.DataFrame([x.values.tolist() for x in captured_values],        columns=['ENHANCER_' + x for x in   out_in.index])\n",
    "  df_out_GENE = pd.DataFrame([x.values.tolist() for x in captured_values_target], columns=['GENE_' + x for x in       out_in.index])\n",
    "\n",
    "  df_out = pd.concat([df_out_ENH, df_out_GENE], axis=1)\n",
    "\n",
    "  df_out.to_csv(OUTPUT_PATH + '/' + MODIFY_PREFIX +'GENERATED_SEQS.TXT', sep='\\t', index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91bac459",
   "metadata": {},
   "source": [
    "# TRAIN_GATA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd834dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eops = EnformerOps()\n",
    "load_tracks_eops(eops) #loading the tracks\n",
    "\n",
    "ran_seqs = all_data[all_data['TAG'].apply(lambda x : x in {'training', 'test', 'validation'})].copy()\n",
    "subset_ran_seqs = ran_seqs[['SEQUENCE', 'ID']]\n",
    "print (all_data[all_data['TAG'].apply(lambda x : x in {'training', 'test', 'validation'})].copy().shape)\n",
    "print (ran_seqs['TAG'].unique())\n",
    "\n",
    "#ran_seq_list = subset_ran_seqs.head(3).values.tolist()\n",
    "ran_seq_list = subset_ran_seqs.values.tolist()\n",
    "if DEMO:\n",
    "    ran_seq_list=ran_seq_list[:DEMO_SEQ]\n",
    "\n",
    "\n",
    "\n",
    "captured_values = []\n",
    "captured_values_target = []\n",
    "for e_n, s in enumerate(ran_seq_list): \n",
    "    \n",
    "    try:\n",
    "        s_in = s[1]\n",
    "        id_seq = s[0]   # aways inject a sequence\n",
    "        #print (id_seq)\n",
    "        eops.load_data([id_seq]) # This will be always zero (sequence passed using insert_seq_directly)\n",
    "        list_bw = eops.generate_plot_number(-1, interval_list=ENHANCER_REGION, wildtype=False, \n",
    "                                        show_track=False, modify_prefix=MODIFY_PREFIX) \n",
    "    except RuntimeError:\n",
    "    # Infrequent \"the entries are out of order\" error for some random seqs \n",
    "        continue\n",
    "    try:\n",
    "        out_in = eops.extract_from_position(ENHANCER_REGION, as_dataframe=True)\n",
    "        #print (out_in.shape)\n",
    "        out_in = out_in.mean()\n",
    "        out_in['SEQ_ID'] = s_in\n",
    "        out_in['TARGET_NAME'] = 'ENH_GATA1'\n",
    "        columns_names = out_in.copy()\n",
    "        captured_values.append( out_in  )\n",
    "        \n",
    "        out_in = eops.extract_from_position(GENE_REGION, as_dataframe=True)\n",
    "        #print (out_in.shape)\n",
    "        out_in = out_in.mean()\n",
    "        out_in['SEQ_ID'] = id_seq\n",
    "        out_in['TARGET_NAME'] = 'GATA1_TSS_2K'\n",
    "        columns_names = out_in.copy()\n",
    "        captured_values_target.append( out_in  )\n",
    "        \n",
    "    except ValueError:\n",
    "    # Infrequent \"All arrays must be of the same length\" error\n",
    "        continue\n",
    "\n",
    "    if (e_n !=0) and (e_n % SAVE_INTERVAL )==0:\n",
    "        print ('SAVING', e_n)\n",
    "        df_out_ENH =  pd.DataFrame([x.values.tolist() for x in captured_values],        columns=['ELEMENT_' + x for x in   out_in.index])\n",
    "        df_out_GENE = pd.DataFrame([x.values.tolist() for x in captured_values_target], columns=['TSS_' + x for x in       out_in.index])\n",
    "\n",
    "        df_out = pd.concat([df_out_ENH, df_out_GENE], axis=1)\n",
    "\n",
    "        df_out.to_csv(OUTPUT_PATH + '/' + MODIFY_PREFIX +'TRAIN_VAL_TEST_GATA1_SEQS.TXT', sep='\\t', index=None)\n",
    "\n",
    "\n",
    "print ('SAVING', e_n, 'TRAIN_VAL_TEST Final_saving')\n",
    "df_out_ENH =  pd.DataFrame([x.values.tolist() for x in captured_values],        columns=['ELEMENT_' + x for x in   out_in.index])\n",
    "df_out_GENE = pd.DataFrame([x.values.tolist() for x in captured_values_target], columns=['TSS_' + x for x in       out_in.index])\n",
    "\n",
    "df_out = pd.concat([df_out_ENH, df_out_GENE], axis=1)\n",
    "\n",
    "df_out.to_csv(OUTPUT_PATH + '/' + MODIFY_PREFIX +'TRAIN_VAL_TEST_GATA1_SEQS.TXT', sep='\\t', index=None)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "asGb7Rj7CosW",
    "0D00-sjkBxFg",
    "xfwwNBUgAowH",
    "GhL-VE94D94Y",
    "gjnffPDM3gkl"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "5_31_2023_enformer_CAGE_DNAse_bias_experiment.ipynb",
   "output_path": "demo_out.ipynb",
   "parameters": {},
   "start_time": "2023-06-03T00:24:41.823587",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "268164aa6ef64c8d97402b4ce4e06ae2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40cf2bd585184927bc3333c4f3e2c8c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "878a4abafd5d419aab5bf5471fe881a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b2ea8599b45d479aa52394c1396a719c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b44c7e57bda24c85b8101536a9190f55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c26f99b3c969461fa0103907b836ebda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_268164aa6ef64c8d97402b4ce4e06ae2",
      "placeholder": "​",
      "style": "IPY_MODEL_eb1314c835b84e18afbe1a279477da5c",
      "value": " 1/3336 [05:26&lt;152:59:35, 165.15s/it]"
     }
    },
    "c698df1eda1e431cbb5bb93b9b4fc9fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2a96bc89787463a8260a67069db4411": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2ea8599b45d479aa52394c1396a719c",
      "placeholder": "​",
      "style": "IPY_MODEL_b44c7e57bda24c85b8101536a9190f55",
      "value": "  0%"
     }
    },
    "e729baeee6934b41b6e23821ed33f6e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e2a96bc89787463a8260a67069db4411",
       "IPY_MODEL_f4d4e4ad0db441bab2ce53d84df8d471",
       "IPY_MODEL_c26f99b3c969461fa0103907b836ebda"
      ],
      "layout": "IPY_MODEL_c698df1eda1e431cbb5bb93b9b4fc9fa"
     }
    },
    "eb1314c835b84e18afbe1a279477da5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4d4e4ad0db441bab2ce53d84df8d471": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40cf2bd585184927bc3333c4f3e2c8c8",
      "max": 3336,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_878a4abafd5d419aab5bf5471fe881a8",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
